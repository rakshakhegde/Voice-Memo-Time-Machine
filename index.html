<!doctype html>
<html lang="en">

<link rel="icon" type="image/x-icon" href="voice_memo_time_machine.ico">

<head>
  <meta charset="utf-8" />
  <meta name="viewport" content="width=device-width,initial-scale=1" />
  <title>Voice Memo Time Machine</title>
  <style>
    :root {
      --bg: #0b0f12;
      --card: #0f1620;
      --muted: #8b98a6;
      --accent: #6ee7b7;
      --danger: #ff6b6b;
      --glass: rgba(255, 255, 255, 0.03);
    }

    html,
    body {
      height: 100%;
      margin: 0;
      background: var(--bg);
      color: #e6eef6;
      font-family: Inter, ui-sans-serif, system-ui, Segoe UI, Roboto, "Helvetica Neue", Arial;
    }

    .app {
      max-width: 1100px;
      margin: 28px auto;
      padding: 24px;
      display: grid;
      grid-template-columns: 360px 1fr;
      gap: 20px;
    }

    .panel {
      background: linear-gradient(180deg, rgba(255, 255, 255, 0.02), transparent);
      border-radius: 14px;
      padding: 18px;
      box-shadow: 0 6px 30px rgba(0, 0, 0, 0.6);
      border: 1px solid rgba(255, 255, 255, 0.03);
    }

    h1 {
      margin: 0 0 10px 0;
      font-size: 18px
    }

    .muted {
      color: var(--muted);
      font-size: 13px
    }

    select,
    button {
      background: transparent;
      border: 1px solid rgba(255, 255, 255, 0.06);
      padding: 10px;
      border-radius: 10px;
      color: inherit;
      font-size: 14px
    }

    .controls {
      display: flex;
      flex-direction: column;
      gap: 12px
    }

    .row {
      display: flex;
      gap: 10px;
      align-items: center
    }

    .durations {
      display: flex;
      flex-wrap: wrap;
      gap: 8px
    }

    .dur-btn {
      padding: 8px 12px;
      border-radius: 999px;
      background: var(--glass);
      cursor: pointer;
      border: 1px solid rgba(255, 255, 255, 0.02)
    }

    .dur-btn:hover {
      transform: translateY(-2px)
    }

    .status {
      font-size: 12px;
      color: var(--muted)
    }

    .meter {
      height: 10px;
      border-radius: 8px;
      background: linear-gradient(90deg, rgba(255, 255, 255, 0.04), rgba(255, 255, 255, 0.02));
      overflow: hidden
    }

    .level {
      height: 100%;
      width: 0;
      background: linear-gradient(90deg, var(--accent), #2ad1a3)
    }

    canvas {
      width: 100%;
      height: 120px;
      border-radius: 10px;
      background: linear-gradient(180deg, rgba(255, 255, 255, 0.01), rgba(255, 255, 255, 0.00));
      display: block
    }

    .right {
      display: flex;
      flex-direction: column;
      gap: 16px;
    }

    .snippet-card {
      display: flex;
      flex-direction: column;
      gap: 8px;
      padding: 12px;
      background: linear-gradient(180deg, rgba(255, 255, 255, 0.015), transparent);
      border-radius: 12px;
      border: 1px solid rgba(255, 255, 255, 0.02)
    }

    .snippet-controls {
      display: flex;
      gap: 10px;
      align-items: center
    }

    .player {
      display: flex;
      flex: 1;
      gap: 12px;
    }

    audio {
      width: 100%;
      border-radius: 8px;
    }

    .download {
      padding: 8px 12px;
      border-radius: 10px;
      background: transparent;
      border: 1px solid rgba(255, 255, 255, 0.06);
      cursor: pointer
    }

    .small {
      font-size: 13px
    }

    .device-label {
      font-weight: 600
    }

    .hint {
      font-size: 12px;
      color: var(--muted)
    }

    footer {
      color: var(--muted);
      font-size: 12px;
      text-align: center;
      margin-top: 12px
    }

    .warning {
      color: var(--danger);
      font-size: 13px
    }

    @media (max-width:880px) {
      .app {
        grid-template-columns: 1fr;
        padding: 12px
      }
    }

    #liveClock {
      white-space: nowrap;
      font-variant-numeric: tabular-nums;
    }

    /* --- Custom logger styles --- */
    .logger-container {
      background: var(--glass);
      border-radius: 8px;
      padding: 0 10px;
      border: 1px solid rgba(255, 255, 255, 0.02);
    }

    .log-title-row {
      display: flex;
      justify-content: space-between;
      align-items: center;
      cursor: pointer;
      padding: 8px 0;
    }

    .log-header {
      font-size: 12px;
      font-weight: 600;
      color: #e6eef6;
      margin-left: 2px;
    }

    .arrow {
      font-size: 8px;
      transition: transform 0.2s;
      margin-right: 5px;
    }

    .arrow.collapsed {
      transform: rotate(-90deg);
    }

    .log-content {
      overflow-y: auto;
      max-height: 200px;
      transition: all 0.3s ease-in-out;
      border-top: 1px solid rgba(255, 255, 255, 0.05);
      padding: 8px 0;
    }

    .log-content.collapsed {
      max-height: 0;
      padding: 0;
      overflow: hidden;
      border-top: none;
    }

    #logger {
      font-size: 11px;
      color: var(--muted);
      white-space: nowrap;
      width: 200px;
    }

    .small-btn {
      padding: 4px 8px;
      font-size: 10px;
      border-radius: 6px;
      background: rgba(255, 255, 255, 0.06);
      border: 1px solid rgba(255, 255, 255, 0.08);
      cursor: pointer;
      margin-left: 10px;
    }

    .log-control {
      display: flex;
      align-items: center;
    }
  </style>
</head>

<body>
  <div class="app">
    <div class="panel">
      <h1 style="cursor: pointer;" onclick="window.open('voice_memo_time_machine.jpg', '_blank')">
        <img src="voice_memo_time_machine.ico" style="height: 1.2em; vertical-align: middle; margin-right: 8px;"
          alt="favicon of voice memo time machine">
        <span style="vertical-align: middle; cursor: pointer;">Rolling Hour Recorder</span>
      </h1>
      <div class="muted">Records continuously (rolling 1 hour). Extract snippets while recording.</div>
      <div style="height:14px"></div>

      <div class="controls">
        <div>
          <div style="display:flex;justify-content:space-between;align-items:end;">
            <div>
              <div class="device-label" id="deviceLabel">Microphone: ‚Äî</div>
              <div class="hint" style="margin-top:0px;">Choose input microphone (default: Macbook Pro Microphone)</div>
            </div>
            <div style="text-align:right">
              <div class="status" id="recStatus">Status: initializing‚Ä¶</div>
              <div class="status" id="srDisplay" style="margin-top:2px;">Sample rate: ‚Äî</div>
            </div>
          </div>
          <div style="height:10px"></div>
          <div class="row">
            <select id="deviceSelect"></select>
            <button id="restartBtn">Restart</button>
          </div>
        </div>

        <div>
          <div class="muted small">Live waveform (past 30s)</div>
          <canvas id="liveWave" width="800" height="120"></canvas>
          <div style="height:8px"></div>
          <div class="meter">
            <div id="level" class="level"></div>
          </div>
        </div>

        <div>
          <div class="muted small">Extract snippet durations</div>
          <div class="durations" id="durations">
            <button class="dur-btn" data-sec="10">10s</button>
            <button class="dur-btn" data-sec="30">30s</button> <button class="dur-btn" data-sec="60">1m</button>
            <button class="dur-btn" data-sec="120">2m</button> <button class="dur-btn" data-sec="300">5m</button>
            <button class="dur-btn" data-sec="600">10m</button>
            <button class="dur-btn" data-sec="1800">30m</button>
            <button class="dur-btn" data-sec="3600">1h</button>
          </div>
        </div>

        <div>
          <div class="muted small">Storage</div>
          <div class="hint">Buffer: last 1 hour of raw audio (16-bit PCM) ‚Äî memory usage depends on mic sample rate.
          </div>
          <div style="height:8px"></div>
          <div id="memoryInfo" class="muted small">Est. buffer bytes: ‚Äî</div>

          <div style="height:8px;"></div>
          <div class="logger-container" id="loggerContainer">
            <div class="log-title-row">
              <div class="log-control">
                <span class="arrow collapsed" id="logArrow">‚ñº</span>
                <span class="log-header">Logs</span>
              </div>
              <button id="clearLogBtn" class="small-btn">Clear</button>
            </div>
            <div id="logContent" class="log-content collapsed">
              <div id="logger"></div>
            </div>
          </div>
        </div>
      </div>
      <footer>Built ‚Äî Rolling recorder (client-only). No external servers.</footer>
    </div>

    <div class="right">
      <div class="panel">
        <div>
          <div style="overflow: auto;">
            <div id="liveClock" class="muted small" style="float:right; margin-top:2px;">‚Äî</div>
            <div style="font-weight:700;">Snippets</div>
          </div>
          <div class="muted small" style="margin-top:4px;">Choose a duration, or click any existing snippet to inspect
          </div>
        </div>

        <div id="no-snippet-msg" class="muted small" style="margin-top:8px;">No snippet selected yet. Click a duration
          to extract.</div>
        <div id="snippetsArea" style="margin-top:12px;display:flex;flex-direction:column;gap:12px">
        </div>
      </div>

      <div class="panel">
        <div class="muted small">Notes & tips</div>
        <ul class="muted small">
          <li>Allow microphone access when prompted. The app will start recording automatically after permission.</li>
          <li>Snippets are generated client-side as WAV files and downloadable.</li>
          <li>If the browser prevents autoplaying audio or starting recording on load, click "Restart" to initialize
            after granting permission.</li>
        </ul>
        <div style="height:10px"></div>
        <div id="warnBox" class="warning" style="display:none"></div>
      </div>
    </div>
  </div>

  <script>
    /*
     Rolling Hour Recorder with AudioWorklet (single-file)
     - circular buffer: Int16Array storing mono PCM for last 1 hour
     - inline AudioWorklet module created from a Blob
     - live waveform (30s) and snippet extraction to WAV
    */

    (async function () {
      const MAX_SNIPPETS = 10;
      // UI references
      const deviceSelect = document.getElementById('deviceSelect');
      const deviceLabel = document.getElementById('deviceLabel');
      const srDisplay = document.getElementById('srDisplay');
      const recStatus = document.getElementById('recStatus');
      const liveWave = document.getElementById('liveWave');
      const liveCtx = liveWave.getContext('2d');
      const levelBar = document.getElementById('level');
      const durationsDiv = document.getElementById('durations');
      const snippetsArea = document.getElementById('snippetsArea');
      const memoryInfo = document.getElementById('memoryInfo');
      const restartBtn = document.getElementById('restartBtn');
      const liveClock = document.getElementById('liveClock');
      const warnBox = document.getElementById('warnBox');

      // Logger UI references (UPDATED)
      const loggerContainer = document.getElementById('loggerContainer');
      const logTitleRow = loggerContainer.querySelector('.log-title-row');
      const logContent = document.getElementById('logContent');
      const loggerDiv = document.getElementById('logger');
      const clearLogBtn = document.getElementById('clearLogBtn');
      const logArrow = document.getElementById('logArrow');

      const noSnippetMsg = document.getElementById('no-snippet-msg');


      // Click to clear logs (UPDATED: now on clear button)
      clearLogBtn.addEventListener('click', (e) => {
        e.stopPropagation(); // Prevent container collapse/expand
        loggerDiv.innerHTML = '';
      });

      // Collapse/Expand functionality
      logTitleRow.addEventListener('click', () => {
        const isCollapsed = logContent.classList.contains('collapsed');
        if (isCollapsed) {
          logContent.classList.remove('collapsed');
          logArrow.classList.remove('collapsed');
        } else {
          logContent.classList.add('collapsed');
          logArrow.classList.add('collapsed');
        }
      });


      // config
      const MAX_SECONDS = 3600; // 1 hour
      const LIVE_SECONDS = 30;  // live waveform window
      let audioContext = null;
      let micStream = null;
      let sourceNode = null;
      let sampleRate = 48000;
      let buffer = null; // Int16Array circular buffer
      let bufferLength = 0;
      let writeIndex = 0;
      let totalSamplesRecorded = 0;
      let recording = false;
      let channelCount = 1;
      let selectedDeviceId = null;
      let deviceList = [];
      let lastClickedSnippet = null;
      let reuseBuffer = null;

      let lastUsedMicLabel = localStorage.getItem('lastUsedMicLabel') || 'MacBook Pro Microphone';
      let lastUsedDeviceId = localStorage.getItem('lastUsedDeviceId');

      // Inline AudioWorklet code
      const workletCode = `
        class RecorderProcessor extends AudioWorkletProcessor {
          constructor() {
            super();
            // Buffer to hold the converted Int16 data for posting back
            this.int16Buffer = new Int16Array(128); 
          }
          
          process(inputs) {
            const input = inputs[0];
            if (input && input.length > 0) {
              const ch0 = input[0]; // This is the input Float32Array (read-only reference)
              
              // Convert floats from the input channel (ch0) to int16
              // Calculate RMS while converting
              let sumOfSquares = 0;

              for (let i = 0; i < ch0.length; i++) {
                // Clamp the float value between -1 and 1
                const s = Math.max(-1, Math.min(1, ch0[i]));
                
                // Convert to Int16
                const int16 = (s < 0 ? s * 32768 : s * 32767) | 0;
                
                this.int16Buffer[i] = int16;

                sumOfSquares += s * s;
              }

              const rms = Math.sqrt(sumOfSquares / ch0.length);

              this.port.postMessage({
                  intSamples: this.int16Buffer,
                  rms: rms
              });
            }
            return true;
          }
        }
        registerProcessor('recorder-processor', RecorderProcessor);
      `;
      const workletBlob = new Blob([workletCode], { type: 'application/javascript' });
      const workletURL = URL.createObjectURL(workletBlob);

      let recorderNode;

      // Start initialization
      log('await initAndStart start');
      await initAndStart();
      log('await initAndStart done');

      // UI wiring
      log('restart UI wiring');
      restartBtn.onclick = async () => { await restart(); };
      deviceSelect.onchange = async () => { selectedDeviceId = deviceSelect.value; await restart(); };
      durationsDiv.addEventListener('click', async ev => {
        const btn = ev.target.closest('.dur-btn');
        if (!btn) return;
        const seconds = Number(btn.dataset.sec);
        await createSnippet(seconds);
      });

      // ---------- Initialization ----------
      async function initAndStart() {
        log('initAndStart');
        try {
          await startRecordingWithWorklet();
          recStatus.textContent = 'Status: Recording';
          recording = true;
        } catch (err) {
          console.error('init error', err);
          recStatus.textContent = 'Status: ‚ùå Stopped';
          warnBox.style.display = 'block';
          warnBox.textContent = 'Microphone access required ‚Äî click "Restart" and allow microphone. Some browsers prevent auto-start on load.';
        }
        requestAnimationFrame(drawLiveWave);
        setInterval(() => { liveClock.textContent = new Date().toLocaleString(); }, 1000);
      }

      async function restart() {
        log('restart');
        await stopRecording();
        await startRecordingWithWorklet();
      }

      function allocateCircularBuffer() {
        log('allocateCircularBuffer');
        if (sampleRate * MAX_SECONDS == bufferLength) {
          log('Reusing existing circular buffer');
          return;
        }
        bufferLength = sampleRate * MAX_SECONDS;
        buffer = new Int16Array(bufferLength);
        writeIndex = 0;
        totalSamplesRecorded = 0;
        const memoryBytesEstimate = bufferLength * 2;
        memoryInfo.textContent = 'Est. buffer bytes: ' + formatBytes(memoryBytesEstimate) + ' (' + bufferLength + ' samples)';
      }

      function formatBytes(n) {
        if (n > 1e9) return (n / 1e9).toFixed(2) + ' GB';
        if (n > 1e6) return (n / 1e6).toFixed(2) + ' MB';
        if (n > 1e3) return (n / 1e3).toFixed(2) + ' KB';
        return n + ' bytes';
      }

      async function startRecordingWithWorklet() {
        log("üéôÔ∏è unified startRecordingWithWorklet");

        // 1Ô∏è‚É£ Determine which mic to use
        const savedId = selectedDeviceId || localStorage.getItem("lastUsedDeviceId");
        const savedLabel = localStorage.getItem("lastUsedMicLabel");

        // 2Ô∏è‚É£ Step 1: request temp stream (to unlock labels)
        let tempStream = null;
        try {
          if (savedId) {
            tempStream = await navigator.mediaDevices.getUserMedia({
              audio: { deviceId: { exact: savedId } },
            });
          } else {
            tempStream = await navigator.mediaDevices.getUserMedia({ audio: true });
          }
        } catch (err) {
          logToDiv("‚ö†Ô∏è Could not open saved device, falling back to default mic:", err);
          tempStream = await navigator.mediaDevices.getUserMedia({ audio: true });
        }

        // 3Ô∏è‚É£ Step 2: enumerate devices (labels now available)
        const devices = (await navigator.mediaDevices.enumerateDevices())
          .filter((d) => d.kind === "audioinput");

        // 4Ô∏è‚É£ Step 3: pick the correct device using hybrid logic
        let chosenDevice =
          devices.find((d) => d.deviceId === savedId) ||
          devices.find((d) => d.label === savedLabel) ||
          devices.find((d) => d.label == 'MacBook Pro Microphone') ||
          devices[0];

        if (!chosenDevice) {
          recStatus.textContent = '‚ùå No input devices available.';
          return;
        }

        logToDiv("üéß Chosen mic:", chosenDevice.label, chosenDevice.deviceId);

        // 5Ô∏è‚É£ Step 4: update dropdown UI
        deviceSelect.innerHTML = "";
        devices.forEach((d) => {
          const opt = document.createElement("option");
          opt.value = d.deviceId;
          opt.textContent = d.label || `Microphone ${deviceSelect.length + 1}`;
          deviceSelect.appendChild(opt);
        });
        deviceSelect.value = chosenDevice.deviceId;
        deviceLabel.textContent = "Microphone: " + (chosenDevice.label || "Unknown");

        // 6Ô∏è‚É£ Step 5: update persistent info
        localStorage.setItem("lastUsedDeviceId", chosenDevice.deviceId);
        localStorage.setItem("lastUsedMicLabel", chosenDevice.label || "");
        selectedDeviceId = chosenDevice.deviceId;

        // 7Ô∏è‚É£ Step 6: reuse or reopen mic stream
        const tempTrack = tempStream.getAudioTracks()[0];
        const tempDeviceId = tempTrack.getSettings().deviceId;

        if (tempDeviceId === chosenDevice.deviceId) {
          logToDiv("‚ôªÔ∏è Reusing existing tempStream for chosen mic:", chosenDevice.label);
          micStream = tempStream;
        } else {
          logToDiv("üîÑ Opening new stream for chosen mic:", chosenDevice.label);
          tempStream.getTracks().forEach((t) => t.stop());
          micStream = await navigator.mediaDevices.getUserMedia({
            audio: { deviceId: { exact: chosenDevice.deviceId } },
          });
        }

        // 8Ô∏è‚É£ Step 7: setup AudioContext and worklet
        if (!audioContext || audioContext.state === 'closed') {
          audioContext = new (window.AudioContext || window.webkitAudioContext)();
          sampleRate = audioContext.sampleRate;
          srDisplay.textContent = 'Sample rate: ' + sampleRate + ' Hz';
          allocateCircularBuffer();
          audioContext.onstatechange = () => {
            logToDiv(`üéß AudioContext state: ${audioContext.state}`);
          };
        } else if (audioContext.state === 'suspended') {
          await audioContext.resume();
        }

        if (!audioContext.workletModuleLoaded) {
          await audioContext.audioWorklet.addModule(workletURL);
          audioContext.workletModuleLoaded = true;

          // Optional: only revoke if you re-create workletURL each time
          // URL.revokeObjectURL(workletURL);
        }

        recorderNode?.disconnect();
        recorderNode = new AudioWorkletNode(audioContext, "recorder-processor");

        recorderNode.port.onmessage = (event) => {
          writeToCircularBuffer(event.data.intSamples);
          updateLevelMeter(event.data.rms);
        };
        recorderNode.onprocessorerror = (err) => {
          logToDiv('‚ùå Recorder processor error:', err);
        };

        // Connect mic ‚Üí worklet ‚Üí destination (optional for monitoring)
        try { sourceNode?.disconnect(); } catch (e) {
          logToDiv('sourceNode disconnect error', e);
        }
        sourceNode = audioContext.createMediaStreamSource(micStream);
        sourceNode.connect(recorderNode);
        // recorderNode.connect(audioContext.destination); // uncomment to hear yourself
        // connect a gain of 0 to destination if some browsers require a connection to destination
        // but we avoid audible output by not connecting workletNode to destination.
        recStatus.textContent = 'Status: Recording';
        recording = true;

        logToDiv("üé¨ Recording started with:", chosenDevice.label);
      }

      function stopRecording() {
        log('stopRecording');
        if (micStream) {
          micStream.getTracks().forEach(t => t.stop());
          micStream = null;
        }
        if (sourceNode) {
          try { sourceNode.disconnect(); } catch (e) {
            log('sourceNode disconnect error', e);
          }
          sourceNode = null;
        }
        recStatus.textContent = 'Status: ‚ùå Stopped';
        recording = false;
      }

      function writeToCircularBuffer(intSamples) {
        for (let i = 0; i < intSamples.length; i++) {
          buffer[writeIndex] = intSamples[i];
          writeIndex++;
          totalSamplesRecorded++;
          if (writeIndex >= bufferLength) writeIndex = 0;
        }
      }

      function updateLevelMeter(rms) {
        levelBar.style.width = Math.min(1, rms * 4) * 100 + '%';
      }

      // ---------- Snippet extraction ----------
      function extractLastNSeconds(seconds) {
        log('extractLastNSeconds');
        if (!buffer) return new Int16Array(0);

        const samplesNeeded = Math.min(Math.floor(sampleRate * seconds), bufferLength);
        const result = new Int16Array(samplesNeeded);
        let start = writeIndex - samplesNeeded;
        if (start < 0) start += bufferLength;
        if (start + samplesNeeded <= bufferLength) {
          result.set(buffer.subarray(start, start + samplesNeeded), 0);
        } else {
          const firstPart = bufferLength - start;
          result.set(buffer.subarray(start, start + firstPart), 0);
          result.set(buffer.subarray(0, samplesNeeded - firstPart), firstPart);
        }
        return result;
      }

      function extractLastNSecondsForLive() {
        log('extractLastNSecondsForLive');
        if (!buffer) return new Int16Array(0);
        const requiredSize = LIVE_SECONDS * sampleRate;
        const availableSamples = Math.min(requiredSize, bufferLength);
        // reuse an Int16Array pool (store raw int16 PCM)
        if (!reuseBuffer || reuseBuffer.length !== availableSamples) {
          reuseBuffer = new Int16Array(availableSamples);
        }
        const result = reuseBuffer;
        const total = availableSamples;
        let start = writeIndex - total;
        if (start < 0) start += bufferLength;
        if (start + total <= bufferLength) {
          // contiguous
          result.set(buffer.subarray(start, start + total), 0);
        } else {
          // wrapped
          const firstPart = bufferLength - start;
          result.set(buffer.subarray(start, start + firstPart), 0);
          result.set(buffer.subarray(0, total - firstPart), firstPart);
        }
        return result.subarray(0, total);
      }

      function makeWavBlob(intSamples) {
        const numChannels = 1;
        const sampleRateLocal = sampleRate;
        const bufferLen = intSamples.length * 2; // 2 bytes per sample
        const wavBuffer = new ArrayBuffer(44 + bufferLen);
        const view = new DataView(wavBuffer);

        function writeString(dataview, offset, str) {
          for (let i = 0; i < str.length; i++) dataview.setUint8(offset + i, str.charCodeAt(i));
        }

        // Write WAV header
        writeString(view, 0, 'RIFF');
        view.setUint32(4, 36 + bufferLen, true);
        writeString(view, 8, 'WAVE');
        writeString(view, 12, 'fmt ');
        view.setUint32(16, 16, true);
        view.setUint16(20, 1, true);
        view.setUint16(22, numChannels, true);
        view.setUint32(24, sampleRateLocal, true);
        view.setUint32(28, sampleRateLocal * numChannels * 2, true);
        view.setUint16(32, numChannels * 2, true);
        view.setUint16(34, 16, true);
        writeString(view, 36, 'data');
        view.setUint32(40, bufferLen, true);

        // Write PCM data
        let offset = 44;
        for (let i = 0; i < intSamples.length; i++, offset += 2) {
          view.setInt16(offset, intSamples[i], true);
        }

        return new Blob([view], { type: 'audio/wav' });
      }

      async function createSnippet(seconds) {
        log('createSnippet');
        recStatus.textContent = 'Status: Creating snippet‚Ä¶';

        const totalRecordedSec = totalSamplesRecorded / sampleRate;
        const actualSeconds = Math.min(seconds, totalRecordedSec);
        if (actualSeconds <= 0) {
          alert('No audio available yet. Wait a few seconds and try again.');
          recStatus.textContent = 'Status: Recording';
          return;
        }

        const intSamples = extractLastNSeconds(actualSeconds);
        const blob = makeWavBlob(intSamples);
        const url = URL.createObjectURL(blob);
        const snippetTime = new Date();

        if (snippetsArea.children.length == 0) noSnippetMsg.style.display = 'none';

        while (snippetsArea.children.length >= MAX_SNIPPETS) {
          snippetsArea.removeChild(snippetsArea.lastChild);
        }

        const card = document.createElement('div');
        card.className = 'snippet-card';
        const header = document.createElement('div');
        header.style.display = 'flex';
        header.style.justifyContent = 'space-between';
        header.style.alignItems = 'center';

        const titleDiv = document.createElement('div');
        titleDiv.style.fontWeight = '700';
        titleDiv.textContent = `${formatSeconds(actualSeconds)} snippet`;
        header.appendChild(titleDiv);

        const dateDiv = document.createElement('div');
        dateDiv.style.display = 'flex';
        dateDiv.style.alignItems = 'center';
        dateDiv.style.gap = '6px';

        const dateText = document.createElement('span');
        dateText.className = 'muted small';
        dateText.textContent = snippetTime.toLocaleString();
        dateDiv.appendChild(dateText);

        const removeBtn = document.createElement('button');
        removeBtn.textContent = '√ó';
        removeBtn.style.background = 'transparent';
        removeBtn.style.border = 'none';
        removeBtn.style.color = 'var(--danger)';
        removeBtn.style.cursor = 'pointer';
        removeBtn.style.fontSize = '14px';
        removeBtn.onclick = () => {
          snippetsArea.removeChild(card);
          if (snippetsArea.children.length === 0) noSnippetMsg.style.display = 'block';
        };
        dateDiv.appendChild(removeBtn);

        header.appendChild(dateDiv);
        card.appendChild(header);


        // waveform canvas (HiDPI)
        const canvas = document.createElement('canvas');
        canvas.style.width = '100%';
        canvas.style.height = '120px';
        const dpr = window.devicePixelRatio || 1;
        const parentWidth = Math.max(800, snippetsArea.clientWidth || 800);
        canvas.width = Math.round(parentWidth * dpr);
        canvas.height = Math.round(120 * dpr);
        card.appendChild(canvas);
        drawSnippetWaveform(intSamples, canvas);

        // audio controls + download
        const controls = document.createElement('div');
        controls.className = 'snippet-controls';
        const playerWrap = document.createElement('div');
        playerWrap.className = 'player';

        const audio = document.createElement('audio');
        audio.controls = true;
        audio.src = url;
        audio.preload = 'auto';
        playerWrap.appendChild(audio);
        card.audio = audio;

        const dl = document.createElement('button');
        dl.className = 'download';
        dl.textContent = 'Download';
        dl.onclick = () => {
          const stamp = snippetTime;
          const timeStr = stamp.toLocaleTimeString([], { hour: '2-digit', minute: '2-digit', second: '2-digit', hour12: true })
            .replaceAll(':', '-').replace(/\s/g, '');
          const dateStr = stamp.toLocaleDateString([], { month: 'numeric', day: 'numeric', year: 'numeric' })
            .replaceAll('/', '-');
          const name = `${formatSeconds(actualSeconds)} ${timeStr} ${dateStr} audio-timemachine.wav`;
          const a = document.createElement('a');
          a.href = url;
          a.download = name;
          a.click();
        };

        controls.appendChild(playerWrap);
        controls.appendChild(dl);
        card.appendChild(controls);
        snippetsArea.prepend(card);

        audio.addEventListener('play', () => {
          for (const p of snippetsArea.children) {
            if (p.audio && p.audio !== audio) {
              p.audio.pause();
            }
          }
          lastClickedSnippet = audio;
        });
        audio.addEventListener('click', () => { lastClickedSnippet = audio; });

        canvas.addEventListener('click', () => {
          lastClickedSnippet = audio;
          audio.play();
        });

        playerSeekUI(audio, canvas, intSamples);

        recStatus.textContent = 'Status: Recording';
      }

      // show playback progress overlay on snippet waveform
      function playerSeekUI(audio, canvasEl, intSamples) {
        const ctx = canvasEl.getContext('2d');
        const w = canvasEl.width;
        const h = canvasEl.height;
        function drawProgress() {
          drawSnippetWaveform(intSamples, canvasEl);
          const pct = audio.duration ? (audio.currentTime / audio.duration) : 0;
          ctx.fillStyle = 'rgba(100,255,200,0.08)';
          ctx.fillRect(0, 0, Math.max(2, pct * w), h);
          ctx.fillStyle = 'rgba(255,255,255,0.08)';
          ctx.fillRect(Math.max(0, pct * w - 1), 0, 2, h);
        }
        audio.addEventListener('timeupdate', drawProgress);
        canvasEl.addEventListener('click', (ev) => {
          const rect = canvasEl.getBoundingClientRect();
          const x = ev.clientX - rect.left;
          let percent = x / rect.width;
          if (percent <= 0.03) percent = 0;
          if (audio.duration) audio.currentTime = percent * audio.duration;
          drawProgress();
        });
      }

      // waveform drawing for canvas (handles HiDPI canvas sizes)
      function drawSnippetWaveform(intSamples, canvasEl) {
        const ctx = canvasEl.getContext('2d');
        const w = canvasEl.width;
        const h = canvasEl.height;

        // Clear the canvas
        ctx.clearRect(0, 0, w, h);

        // Background gradient
        const g = ctx.createLinearGradient(0, 0, 0, h);
        g.addColorStop(0, 'rgba(255,255,255,0.01)');
        g.addColorStop(1, 'rgba(255,255,255,0.00)');
        ctx.fillStyle = g;
        ctx.fillRect(0, 0, w, h);

        // Draw the waveform
        ctx.lineWidth = 1;
        ctx.strokeStyle = 'rgba(110,231,183,0.95)';
        ctx.beginPath();

        const pixelWidth = w; // Number of vertical lines to draw
        const step = Math.max(1, Math.ceil(intSamples.length / pixelWidth)); // Samples per pixel column

        for (let i = 0; i < pixelWidth; i++) {
          const start = i * step;
          let min = 32767, max = -32768; // Int16 range

          // Find min and max values for the current column
          for (let j = 0; j < step && (start + j) < intSamples.length; j++) {
            const sample = intSamples[start + j];
            if (sample < min) min = sample;
            if (sample > max) max = sample;
          }

          // Scale min and max to canvas height
          const y1 = ((1 - (min / 32768)) / 2) * h;
          const y2 = ((1 - (max / 32768)) / 2) * h;

          // Draw the line for this column
          ctx.moveTo(i, y1);
          ctx.lineTo(i, y2);
        }

        ctx.stroke();
      }

      // live waveform draw loop
      let lastDraw = 0;
      function drawLiveWave() {
        const now = performance.now();
        if (now - lastDraw < 200) { requestAnimationFrame(drawLiveWave); return; }
        lastDraw = now;

        const canvas = liveWave;
        const ctx = liveCtx;
        const dpr = devicePixelRatio || 1;
        const wCss = canvas.clientWidth;
        const hCss = canvas.clientHeight;
        const w = Math.round(wCss * dpr);
        const h = Math.round(hCss * dpr);
        if (canvas.width !== w || canvas.height !== h) {
          canvas.width = w;
          canvas.height = h;
        }

        ctx.clearRect(0, 0, w, h);
        ctx.save();
        ctx.scale(dpr, dpr);
        ctx.lineWidth = 1.2;
        ctx.strokeStyle = 'rgba(110,231,183,0.95)';
        ctx.beginPath();

        // extract returns Int16Array now (raw PCM). compute min/max in int domain then scale once.
        const samples = extractLastNSecondsForLive();
        if (samples.length > 0) {
          const step = Math.max(1, Math.floor(samples.length / wCss));
          for (let x = 0; x < wCss; x++) {
            const start = x * step;
            let minInt = 32767, maxInt = -32768;
            for (let k = 0; k < step && (start + k) < samples.length; k++) {
              const vInt = samples[start + k];
              if (vInt < minInt) minInt = vInt;
              if (vInt > maxInt) maxInt = vInt;
            }
            // scale to [-1,1]
            const min = minInt / 32768;
            const max = maxInt / 32768;
            const y1 = (1 - (min + 1) / 2) * hCss;
            const y2 = (1 - (max + 1) / 2) * hCss;
            ctx.moveTo(x, y1);
            ctx.lineTo(x, y2);
          }
          ctx.stroke();
        } else {
          ctx.fillStyle = 'rgba(255,255,255,0.03)';
          ctx.font = '12px system-ui';
          ctx.fillText('waiting for audio‚Ä¶', 12, 18);
        }

        ctx.restore();
        requestAnimationFrame(drawLiveWave);
      }

      function formatSeconds(s) {
        s = Math.trunc(s);
        const h = Math.floor(s / 3600);
        const m = Math.floor((s % 3600) / 60);
        const sec = s % 60;

        if (h > 0) {
          return `${h}h${m ? m + 'm' : ''}${sec ? sec + 's' : ''}`;
        } else if (m > 0) {
          return `${m}m${sec ? sec + 's' : ''}`;
        } else {
          return `${sec}s`;
        }
      }

      // cleanup on page unload
      window.addEventListener('unload', () => { if (micStream) micStream.getTracks().forEach(t => t.stop()); });

      // spacebar toggles play/pause for last clicked snippet
      window.addEventListener('keydown', ev => {
        if (ev.code === 'Space') {
          ev.preventDefault();

          if (lastClickedSnippet) {
            // toggle play/pause for the last clicked snippet
            if (lastClickedSnippet.paused) lastClickedSnippet.play();
            else lastClickedSnippet.pause();
          } else {
            // fallback: play the first snippet if available
            const firstAudio = snippetsArea.querySelector('audio');
            if (firstAudio) {
              firstAudio.play();
              lastClickedSnippet = firstAudio;
            }
            // if no audio exists, do nothing
          }
        }
      });

      window.addEventListener('visibilitychange', () => {
        const track = micStream?.getAudioTracks?.()[0];
        if (document.hidden) {
          logToDiv('Background', audioContext?.state, track?.readyState);
        } else {
          logToDiv('Foreground', audioContext?.state, track?.readyState);
          //audioContext?.resume();
        }
      });

      function log(...msg) {
        console.log(...msg);
      }

      function logToDiv(...msg) {
        //log(...msg);
        const timestamp = new Date().toLocaleTimeString();
        const message = msg.map(m => (typeof m === 'string' ? m : JSON.stringify(m))).join(' ');

        const line = document.createElement('div');
        line.textContent = `[${timestamp}] ${message}`;
        loggerDiv.appendChild(line);

        // Auto-scroll to bottom
        logContent.scrollTop = logContent.scrollHeight;
      }


    })();
  </script>
</body>

</html>